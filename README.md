
# Advanced Time Series Forecasting with Attention-based Transformers

This project implements a multivariate multi-step forecasting model using a seq2seq Transformer.
Includes:
- Data loading & preprocessing (windowing, normalization)
- Transformer encoder–decoder model
- Training loop
- Evaluation vs ARIMA baseline
- Hyperparameter tuning notes

Files:
- main.py — full model code
- report.md — 350-word project description
- github_description.md — 350-word GitHub summary
- requirements.txt
